{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Створення набору даних за допомогою DatasetGenerator\n",
    "Для генерації набору даних можна використовувати функцію make_classification з бібліотеки scikit-learn. Вона дозволяє створити набір даних із заданими характеристиками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.125100   1.178124   0.493516   0.790880  -0.614278   1.347020   \n",
      "1  -0.564641   3.638629  -1.522415  -1.541705   1.616697   4.781310   \n",
      "2   0.516313   2.165426  -0.628486  -0.386923   0.492518   1.442381   \n",
      "3   0.537282   0.966618  -0.115420   0.670755  -0.958516   0.871440   \n",
      "4   0.278385   1.065828  -1.724917  -2.235667   0.715107   0.731249   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  target  \n",
      "0   1.419515   1.357325   0.966041  -1.981139       1  \n",
      "1   3.190292  -0.890254   1.438826  -3.828748       0  \n",
      "2   1.332905  -1.958175  -0.348803  -1.804124       0  \n",
      "3   0.508186  -1.034471  -1.654176  -1.910503       1  \n",
      "4  -0.674119   0.598330  -0.524283   1.047610       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Генеруємо набір даних\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,  # кількість зразків\n",
    "    n_features=10,   # кількість ознак\n",
    "    n_informative=5, # кількість інформативних ознак\n",
    "    n_redundant=2,   # кількість надлишкових ознак\n",
    "    n_classes=2,     # кількість класів\n",
    "    random_state=42  # для відтворюваності\n",
    ")\n",
    "\n",
    "# Перетворюємо на DataFrame\n",
    "df_generated = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\n",
    "df_generated['target'] = y\n",
    "\n",
    "print(df_generated.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Завантаження набору даних із Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перші рядки датасету:\n",
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
      "0             0.00            0.00  ...           0.00          0.000   \n",
      "1             0.00            0.94  ...           0.00          0.132   \n",
      "2             0.64            0.25  ...           0.01          0.143   \n",
      "3             0.31            0.63  ...           0.00          0.137   \n",
      "4             0.31            0.63  ...           0.00          0.135   \n",
      "\n",
      "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
      "0            0.0          0.778          0.000          0.000   \n",
      "1            0.0          0.372          0.180          0.048   \n",
      "2            0.0          0.276          0.184          0.010   \n",
      "3            0.0          0.137          0.000          0.000   \n",
      "4            0.0          0.135          0.000          0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  class  \n",
      "0                       278      1  \n",
      "1                      1028      1  \n",
      "2                      2259      1  \n",
      "3                       191      1  \n",
      "4                       191      1  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "\n",
      "Інформація про дані:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_%3B               4601 non-null   float64\n",
      " 49  char_freq_%28               4601 non-null   float64\n",
      " 50  char_freq_%5B               4601 non-null   float64\n",
      " 51  char_freq_%21               4601 non-null   float64\n",
      " 52  char_freq_%24               4601 non-null   float64\n",
      " 53  char_freq_%23               4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  class                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n",
      "None\n",
      "\n",
      "Кількість пропущених значень:\n",
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_%3B                 0\n",
      "char_freq_%28                 0\n",
      "char_freq_%5B                 0\n",
      "char_freq_%21                 0\n",
      "char_freq_%24                 0\n",
      "char_freq_%23                 0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "class                         0\n",
      "dtype: int64\n",
      "\n",
      "Матриця плутанини:\n",
      "[[522   9]\n",
      " [ 32 358]]\n",
      "\n",
      "Класифікаційний звіт:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       531\n",
      "           1       0.98      0.92      0.95       390\n",
      "\n",
      "    accuracy                           0.96       921\n",
      "   macro avg       0.96      0.95      0.95       921\n",
      "weighted avg       0.96      0.96      0.96       921\n",
      "\n",
      "\n",
      "Точність моделі (Accuracy): 0.9554831704668838\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Завантаження даних\n",
    "df = pd.read_csv(\"data set fake bills/spambase_csv.csv\")\n",
    "\n",
    "# Попередній аналіз даних\n",
    "print(\"Перші рядки датасету:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nІнформація про дані:\")\n",
    "print(df.info())\n",
    "\n",
    "# Перевірка пропусків\n",
    "print(\"\\nКількість пропущених значень:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 1. Заповнення пропусків\n",
    "# Використання середнього значення для числових колонок\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# Використання моди для категоріальних колонок\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# 2. Кодування категоріальних змінних\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# 3. Вибір ознак та цільової змінної\n",
    "# Припустимо, що остання колонка — цільова\n",
    "X = df.iloc[:, :-1]  # Всі колонки, окрім останньої\n",
    "y = df.iloc[:, -1]   # Остання колонка\n",
    "\n",
    "# 4. Розподіл на навчальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабування ознак\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 5. Навчання моделі\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Передбачення та оцінка\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nМатриця плутанини:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nКласифікаційний звіт:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nТочність моделі (Accuracy):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Генерація набору даних із використанням Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  feature_2  feature_3  feature_4  target\n",
      "0   0.374540   0.950714   0.731994   0.598658   0.156019       1\n",
      "1   0.155995   0.058084   0.866176   0.601115   0.708073       0\n",
      "2   0.020584   0.969910   0.832443   0.212339   0.181825       0\n",
      "3   0.183405   0.304242   0.524756   0.431945   0.291229       0\n",
      "4   0.611853   0.139494   0.292145   0.366362   0.456070       0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Генерація даних\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "X_custom = np.random.rand(n_samples, n_features)\n",
    "y_custom = (np.sum(X_custom, axis=1) > 2.5).astype(int)\n",
    "\n",
    "# Створення DataFrame\n",
    "df_custom = pd.DataFrame(X_custom, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "df_custom['target'] = y_custom\n",
    "\n",
    "print(df_custom.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Попередня обробка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Навчальна вибірка: (800, 10) (800,)\n",
      "Тестова вибірка: (200, 10) (200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Обробка пропусків\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(df_generated.drop(columns=['target']))\n",
    "\n",
    "# Масштабування даних\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Розділення на навчальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df_generated['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Навчальна вибірка:\", X_train.shape, y_train.shape)\n",
    "print(\"Тестова вибірка:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Оцінка моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 17]\n",
      " [16 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       112\n",
      "           1       0.81      0.82      0.81        88\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.83      0.83      0.83       200\n",
      "weighted avg       0.84      0.83      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Навчання моделі\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Передбачення\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцінка\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
